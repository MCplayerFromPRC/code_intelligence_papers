# Code Intelligence Papers

## Survey

- Gros D, Sezhiyan H, Devanbu P, et al. [Code to Comment “Translation”: Data, Metrics, Baselining & Evaluation](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9286030), ASE 2020.

## Text to Code

### Code Search

### Natural Language to Code

#### Text to Code
- Yin P, Neubig G. [**TRANX**: A transition-based neural abstract syntax parser for semantic parsing and code generation](https://aclanthology.org/D18-2002.pdf), EMNLP 2018.

- 

#### Text to SQL

## Code to code

### Code Translation

#### API Mapping


### Code Completion

## Code to Text

### Code Summarization

- Junyan Cheng, Iordanis Fostiropoulos, Barry Boehm. [GN-Transformer: Fusing Sequence and Graph Representation for Improved Code Summarization](https://arxiv.org/pdf/2111.08874), 2021.

- Shi E, Wang Y, Du L, et al. [CAST: Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees](https://aclanthology.org/2021.emnlp-main.332.pdf), EMNLP 2021.

- LeClair A, Haque S, Wu L, et al. [Improved Code Summarization via a Graph Neural Network](https://arxiv.org/pdf/2004.02843), ICPC 2020.

- Ahmad W, Chakraborty S, Ray B, et al. [A Transformer-based Approach for Source Code Summarization](https://aclanthology.org/2020.acl-main.449.pdf), ACL 2020.

- Wan Y, Zhao Z, Yang M, et al. [Improving automatic source code summarization via deep reinforcement learning](https://arxiv.org/pdf/1811.07234), ASE 2018.


## Pretrained Models

- Karampatsis R M, Sutton C. [**SCELMo**: Source Code Embeddings from Language Models](https://arxiv.org/pdf/2004.13214.pdf), 2020.

- Feng Z, Guo D, Tang D, et al. [**CodeBERT**: A Pre-Trained Model for Programming and Natural Languages](https://aclanthology.org/2020.findings-emnlp.139.pdf). Findings of EMNLP 2020.

- Guo D, Ren S, Lu S, et al. [**GraphCodeBERT**: Pre-training Code Representations with Data Flow](), ICLR 2021.

- Chen M, Tworek J, Jun H, et al. **CodeX**: [Evaluating Large Language Models Trained on Code](https://arxiv.org/pdf/2107.03374.pdf), 2021.

- Lachaux M A, Roziere B, Chanussot L, et al. **TransCoder**: [Unsupervised Translation of Programming Languages](https://papers.nips.cc/paper/2020/file/ed23fbf18c2cd35f8c7f8de44f85c08d-Paper.pdf), NeurIPS 2020.

- Wang Y, Wang W, Joty S, et al. [**CodeT5**: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation](https://aclanthology.org/2021.emnlp-main.685.pdf), EMNLP 2021.

- Ahmad W U, Chakraborty S, Ray B, et al. **PLBART**: [Unified Pre-training for Program Understanding and Generation](https://aclanthology.org/2021.naacl-main.211.pdf), NAACL 2021.

- Roziere B, Lachaux M A, Szafraniec M, et al. [**DOBF**: A Deobfuscation Pre-Training Objective for Programming Languages](https://proceedings.neurips.cc/paper/2021/file/7d6548bdc0082aacc950ed35e91fcccb-Paper.pdf), NeurIPS 2021.

- Clement C, Drain D, Timcheck J, et al. [**PyMT5**: Multi-mode Translation of Natural Language and Python Code with Transformers](https://www.aclweb.org/anthology/2020.emnlp-main.728.pdf), EMNLP 2020.

- Jung T H. [**CommitBERT**: Commit Message Generation Using Pre-Trained Programming Language Model](https://arxiv.org/pdf/2105.14242), 2021.

## Datasets

- Ahmad W U, Tushar M G R, Chakraborty S, et al. [**AVATAR**: A Parallel Corpus for Java-Python Program Translation](https://arxiv.org/pdf/2108.11590), 2021.
- Puri R, Kung D S, Janssen G, et al. [**CodeNet**: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks](https://openreview.net/pdf?id=6vZVBkCDrHT), NeurIPS 2021.

- LeClair A, McMillan C. [Recommendations for Datasets for Source Code Summarization](https://www.aclweb.org/anthology/N19-1394.pdf), NAACL 2019.

## Metrics and Estimation

- Papineni K, Roukos S, Ward T, et al. [**BLEU**: a Method for Automatic Evaluation of Machine Translation](https://aclanthology.org/P02-1040.pdf), ACL 2002.

- Ren S, Guo D, Lu S, et al.   [**CodeBLEU**: a Method for Automatic Evaluation of Code Synthesis](https://arxiv.org/pdf/2009.10297.pdf), 2020.

- Tran N, Tran H, Nguyen S, et al. [Does BLEU Score Work for Code Migration?](https://arxiv.org/pdf/1906.04903), ICPC 2019.

- Agarwal M, Talamadupula K, Houde S, et al. [Quality Estimation & Interpretability for Code Translation](https://openreview.net/pdf?id=U7-z8CD2nYg), NeurIPS 2020 Workshop on Computer-Assisted Programming.

## Benchmark

- Lu S, Guo D, Ren S, et al.
[**CodeXGLUE**: A Machine Learning Benchmark Dataset for Code Understanding and Generation](https://arxiv.org/pdf/2102.04664.pdf), 2021. https://github.com/microsoft/CodeXGLUE.